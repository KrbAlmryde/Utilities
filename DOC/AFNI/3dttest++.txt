Gosset (Student) t-test of sets of 3D datasets.

      [* Also consider program 3dMEMA, which can carry out a  *]
      [* more sophisticated type of 't-test' that also takes  *]
      [* into account the variance map of each input dataset. *]

* Usage can be similar (but not identical) to the old 3dttest; for example:

    3dttest++ -setA a+tlrc'[3]' b+tlrc'[3]' ...

* OR, usage can be similar to 3dMEMA; for example:

    3dttest++ -setA Green sub001 a+tlrc'[3]' \
                          sub002 b+tlrc'[3]' \
                          sub003 c+tlrc'[3]' \
                            ...                \
                -covariates Cfile

* You can input 1 or 2 sets of data (labeled 'A' and 'B').

* With 1 set ('-setA'), the mean across input datasets (usually subjects)
   is tested against 0.

* With 2 sets, the difference in means across each set is tested
   against 0.  The 1 sample results for each set are also provided, since
   these are often of interest to the investigator (e.g., YOU).
  ++ With 2 sets, the default is to produce the difference as setA - setB.
  ++ You can use the option '-BminusA' to get the signs reversed.

* Covariates can be per-dataset (input=1 number) and/or per-voxel/per-dataset
   (input=1 dataset sub-brick).
  ++ Note that voxel-level covariates will slow the program down, since
      the regression matrix for the covariates must be re-inverted for
      each voxel separately.  For most purposes, the program is so fast
      that this slower operation won't be important.

* This program is meant (for many uses) to replace the original 3dttest,
   which was written in 1994, "When grass was green and grain was yellow".
  ++ And when the program's author still had hair.

------------------
SET INPUT OPTIONS
------------------

* At least the '-setA' option must be given.

* '-setB' is optional, and if it isn't used, then the mean of the dataset
   values from '-setA' is t-tested against 0 (1 sample t-test).

* Two forms for the '-setX' (X='A' or 'B') options are allowed.  The first
   (short) form is similar to the original 3dttest program, where the option
   is just followed by a list of datasets to use.

* The second (long) form is similar to the 3dMEMA program, where you specify
   a label for each input dataset sub-brick (a difference between this
   option and the version in 3dMEMA is only that you do not give a second
   dataset ('T_DSET') with each sample in this program).

***** SHORT FORM *****

 -setA BETA_DSET BETA_DSET ...
[-setB]

* In this form of input, you specify the datasets for each set
   directly following the '-setX' option.
  ++ Unlike 3dttest, you can specify multiple sub-bricks in a dataset:
        -setA a+tlrc'[1..13(2)]'
     which inputs 7 sub-bricks at once (1,3,5,7,9,11,13).
  ++ If multiple sub-bricks are input from a single dataset, then
     covariates cannot be used (sorry, Charlie).
  ++ For some limited compatibility with 3dttest, you can use '-set2' in
     place of '-setA', and '-set1' in place of '-setB'.

***** LONG FORM *****

 -setA SETNAME            \
[-setB]  LABL_1 BETA_DSET \
         LABL_2 BETA_DSET \
         ...    ...       \
         LABL_N BETA_DSET

* In this form of input, you specify an overall name for the set of datasets,
   and a label to be associated with each separate input dataset.  (This label
   is used with the '-covariates' option, described later.)

   SETNAME   is the name assigned to the set (used in the output labels).
   LABL_K    is the label for the Kth input dataset name, whose name follows.
   BETA_DSET is the name of the dataset of the beta coefficient or GLT.
             ++ only 1 sub-brick can be specified here!
   Note that the labels 'SETNAME' and 'LABL_K' are limited to 12
   characters -- any more will be thrown away without warning.

     ** The program determines if you are using the short form or long **
     ** form to specify the input datasets based on the first argument **
     ** after the '-setX' option.  If this argument can be opened as a **
     ** dataset, the short form is used. If instead, the next argument **
     ** cannot be opened as a dataset,  then the long form is assumed. **

 -labelA SETNAME = for the short form of '-setX', this option allows you
[-labelB]          to attach a label to the set, which will be used in
                   the sub-brick labels in the output dataset.  If you don't
                   give a SETNAME, then '-setA' will be named 'SetA', etc.

  ***** NOTE WELL: The sign of a two sample test is A - B.          *****
  ***              Thus, '-setB' corresponds to '-set1' in 3dttest,   ***
  ***                and '-setA' corresponds to '-set2' in 3dttest.   ***
  *****            This ordering of A and B matches 3dGroupInCorr.  *****
  *****-------------------------------------------------------------*****
  ***** ALSO NOTE: You can reverse this sign by using the option    *****
  ***              '-BminusA', in which case the test is B - A.       ***
  ***              The option '-AminusB' can be used to explicitly    ***
  *****            specify the standard subtraction order.          *****

--------------------------------------
COVARIATES - per dataset and per voxel
--------------------------------------

 -covariates COVAR_FILE

* COVAR_FILE is the name of a text file with a table for the covariate(s).
   Each column in the file is treated as a separate covariate, and each
   row contains the values of these covariates for one sample (dataset). Note
   that you can use '-covariates' only once -- the COVAR_FILE should contain
   the covariates for ALL input samples from both sets.

* Rows in COVAR_FILE that don't match a dataset label are ignored (silently).

* A dataset label that doesn't match a row in COVAR_FILE, on the other hand,
   is a fatal error.

* There is no provision for missing values -- the entire table must be filled!

* The format of COVAR_FILE is similar to the format used in 3dMEMA and
   3dGroupInCorr (generalized to allow for voxel-wise covariates):

     FIRST LINE -->   subject IQ   age  GMfrac
     LATER LINES -->  Elvis   143   42  Elvis_GM+tlrc[8]
                      Fred     85   59  Fred_GM+tlrc[8]
                      Ethel   109   49  Ethel_GM+tlrc[8]
                      Lucy    133   32  Lucy_GM+tlrc[8]
                      Ricky   121   37  Ricky_GM+tlrc[8]

* The first column contains the labels that must match the dataset
   LABL_K labels given in the '-setX' option(s).

* If you used a short form '-setX' option, each dataset label is
   the dataset's prefix name (truncated to 12 characters).
  ++ e.g.,  fred+tlrc'[3]'  ==>  fred
  ++ e.g.,  elvis.nii.gz    ==>  elvis

* '-covariates' can only be used with the short form '-setX' option
   if each input dataset has only 1 sub-brick (so that each label
   refers to exactly 1 volume of data).
  ++ Duplicate labels in the dataset list or in the covariates file
     will not work well!

* The later columns in COVAR_FILE contain numbers (e.g., 'IQ' and 'age',
    above), or dataset names.  In the latter case, you are specifying a
    voxel-wise covariate (e.g., 'GMfrac').

* A column can contain numbers only, or datasets only.  But one
   column CANNOT contain a mix of numbers and dataset names!

* The first line of COVAR_FILE contains column headers.  The header label
   for the first column isn't used for anything.  The later header labels
   are used in the sub-brick labels stored in the output dataset.

* Only the -paired and -pooled options can be used with covariates.
  ++ If you use -unpooled, it will be changed to -pooled.

* If you use -paired, then the covariate values for setB will be the
   same as those for setA, even if the dataset labels are different!
  ++ If you want to use different covariates for setA and setB in the
     paired test, then you'll have to subtract the setA and setB
     datasets (with 3dcalc), and then do a 1-sample test, using the
     differences of the original covariates as the covariates for
     this 1-sample test.
  ++ This subtraction technique works because a paired t-test is really
     the same as subtracting the paired samples and then doing a
     1-sample t-test on these differences.
  ++ For example, you do FMRI scans on a group of subjects, then
     train them on some task for a week, then re-scan them, and
     you want to use their behavioral scores on the task, pre- and
     post-training, as the covariates.

* See the section 'STRUCTURE OF THE OUTPUT DATASET' for details of
   what is calculated and stored by 3dttest++.

* A maximum of 31 covariates are allowed.  If you have more, then
   seriously consider the likelihood that you are completely deranged.

* N.B.: The simpler forms of the COVAR_FILE that 3dMEMA allows are
        NOT supported here!  Only the format described above will work.

* N.B.: IF you are entering multiple sub-bricks from the same dataset in
        one of the '-setX' options, AND you are using covariates, then
        you must use the 'LONG FORM' of input for the '-setX' option,
        and give each sub-brick a distinct label that matches something
        in the covariates file.  Otherwise, the program will not know
        which covariate to use with which input sub-brick, and bad
        things will happen.

* N.B.: Please be careful in setting up the covariates file and dataset
        labels, as the program only does some simple error checking.
        ++ If you REALLY want to see the regression matrices
           used with covariates, use the '-debug' option.
        ++ Which you give you a LOT of output (to stderr), so redirect:
             3dttest++ .... |& tee debug.out

***** CENTERING (this subject is very important -- read and think!) *******

 ++ This term refers to how the mean across subjects of a covariate
    will be processed.  There are 3 possibilities:

 -center NONE = Do not remove the mean of any covariate.
 -center DIFF = Each set will have the means removed separately.
 -center SAME = The means across both sets will be computed and removed.
                (This option only applies to a 2-sample test, obviously.)

 ++ The default operation is '-center DIFF'.

 ++ '-center NONE' is for the case where you have pre-processed the
    covariate values to meet your needs; otherwise, it is not recommended!

 ++ Centering can be important.  For example, suppose that the mean
    IQ in setA is significantly higher than in setB, and that the beta
    values are positively correlated with IQ.  Then the mean in
    setA will be higher than in setB simply from the IQ effect.
    To attempt to allow for this type of inter-group mean differences,
    you would have to center the two groups together, rather than
    separately (i.e., '-center SAME').

 ++ How to choose between '-center SAME' or '-center DIFF'?  You have
    to understand what your model is and what effect the covariates
    are likely to have on the data.  You shouldn't just blindly us
    covariates 'just in case'.  That way lies statistical madness.
  -- If the two samples don't differ much in the mean values of their
      covariates, then the results with '-center SAME' and '-center DIFF'
      should be nearly the same.
  -- For fixed covariates (not those taken from datasets), the program
      prints out the results of a t-test of the between-group mean
      covariate values.  This test is purely informative; no action is
      taken if the t-test shows that the two groups are significantly
      different in some covariate.
  -- If the two samples DO differ much in the mean values of their
      covariates, then you should read the next point carefully.

 ++ The principal purpose of including covariates in an analysis (ANCOVA)
    is to reduce the variance of the beta values due to extraneous causes.
    Some investigators also wish to use covariates to 'factor out' significant
    differences between groups.  However, there are those who argue
    (convincingly) that if your two groups differ markedly in their mean
    covariate values, then there is NO statistical test that can tell if
    their mean beta values (dependent variable) would be the same or
    different if their covariate values were all the same instead:
      Miller GM and Chapman JP. 'Misunderstanding analysis of covariance',
      J Abnormal Psych 110: 40-48 (2001) 
      http://dx.doi.org/10.1037/0021-843X.110.1.40
      http://psycnet.apa.org/journals/abn/110/1/40.pdf
  -- For example, if all your control subjects have high IQs and all your
      patient subjects have normal IQs, group differences in activation can
      be due to either cause (IQ or disease status) and you can't turn the
      results from a set of high IQ controls into the results you would have
      gotten from a set of normal IQ controls (so you can compare them to the
      patients) just by linear regression and then pretending the IQ issue
      goes away.
  -- The decision as to whether a mean covariate difference between groups
      makes the t-test of the mean beta difference invalid or valid isn't
      purely a statistical question; it's also a question of interpretation
      of the scientific issues of the study.  See the Miller & Chapman paper
      for a lengthy discussion of this issue.
  -- It is not clear how much difference in covariate levels is acceptable.
      You could carry out a t-test on the covariate values between the
      2 groups and if the difference in means is not significant at some
      level (i.e., if p > 0.05?), then accept the two groups as being
      'identical' in that variable.  But this is just a suggestion.
      (In fact, the program now carries out this t-test for you; cf supra.)
  -- Thanks to Andy Mayer for pointing out this article to me.

 ++ At this time, there is no option to force the SLOPES of the
    regression vs. covariate values to be the same in the two-sample
    analysis.  [Adding this feature would be too much like work.]

-------------
OTHER OPTIONS
-------------

 -paired   = Specifies the use of a paired-sample t-test to
              compare setA and setB.  If this option is used,
              setA and setB must have the same cardinality (duh).
             ++ Recall that if '-paired' is used with '-covariates',
                 the covariates for setB will be the same as for setA.

 -unpooled = Specifies that the variance estimates for setA and
              setB be computed separately (not pooled together).
             ++ This only makes sense if -paired is NOT given.
             ++ '-unpooled' cannot be used with '-covariates'.
             ++ Unpooled variance estimates are supposed to
                 provide some protection against heteroscedasticty
                 (significantly different inter-subject variance
                 between the two different collections of datasets).
             ++  Our experience is that for most FMRI data, using
                 '-unpooled' is not needed.

 -toz      = Convert output t-statistics to z-scores
             ++ -unpooled implies -toz, since t-statistics won't be
                 comparable between voxels as the number of degrees
                 of freedom will vary between voxels.

 -zskip [n]= Do not include voxel values that are zero in the analysis.
             ++ This option can be used when not all subjects' datasets
                 overlap perfectly.
             ++ -zskip implies -toz, since the number of samples per
                 voxel will now vary, so the number of degrees of
                 freedom will be spatially variable.
             ++ If you follow '-zskip' with a positive integer (> 1),
                 then that is the minimum number of nonzero values (in
                 each of setA and setB, separately) that must be present
                 before the t-test is carried out.  If you don't give
                 this value, but DO use '-zskip', then its default is 5
                 (for no good reason).
             ++ At this time, you can't use -zskip with -covariates,
                 because that would require more extensive re-thinking
                 and then re-programming.
             ++ You can't use -zskip with -paired, for obvious reasons.
             ++ [This option added 06 Oct 2010 -- RWCox]
             ++ You can also put a decimal fraction between 0 and 1 in
                 place of 'n' (e.g., '0.9', or '90%').  Such a value
                 indicates that at least 90% (e.g.) of the values in each
                 set must be nonzero for the t-test to proceed. [08 Nov 2010]
                 -- In no case will the number of values tested fall below 2!
                 -- You can use '100%' for 'n', to indicate that all data
                    values must be nonzero for the test to proceed.

 -rankize  = Convert the data (and covariates, if any) into ranks before
              doing the 2-sample analyses.  This option is intended to make
              the statistics more 'robust', and is inspired by the paper
                WJ Conover and RL Iman.
                Analysis of Covariance Using the Rank Transformation,
                Biometrics 38: 715-724 (1982).
                http://www.jstor.org/stable/2530051
                Also see http://www.jstor.org/stable/2683975
             ++ Using '-rankize' also implies '-no1sam' (infra), since it
                 doesn't make sense to do 1-sample t-tests on ranks.
             ++ Don't use this option unless you understand what it does!

 -no1sam   = When you input two samples (setA and setB), normally the
              program outputs the 1-sample test results for each set
              (comparing to zero), as well as the 2-sample test results
              for differences between the sets.  With '-no1sam', these
              1-sample test results will NOT be calculated or saved.

 -mask mmm = Only compute results for voxels in the specified mask.
             ++ Voxels not in the mask will be set to 0 in the output.
             ++ If '-mask' is not used, all voxels will be tested.
             ++ HOWEVER: voxels whose input data is constant (in either set)
                 will NOT be processed and will get all zero outputs.  This
                 inaction happens because the variance of a constant set of
                 data is zero, and division by zero is forbidden by the
                 Deities of Mathematics.

 -prefix p = Gives the name of the output dataset file.

 -debug    = Prints out information about the analysis, which can
               be VERY lengthy -- not for general usage.

-------------------------------
STRUCTURE OF THE OUTPUT DATASET
-------------------------------

* The output dataset is stored in float format; there is no option
   to store it in scaled short format :-)

* For each covariate, 2 sub-bricks are produced:
  ++ The estimated slope of the beta values vs covariate
  ++ The t-statistic of this slope
  ++ If there are 2 sets of subjects, then each pair of sub-bricks is
      produced for the setA-setB, setA, and setB cases, so that you'll
      get 6 sub-bricks per covariate (plus 6 more for the mean, which
      is treated as a special covariate whose values are all 1).
  ++ Thus the number of sub-bricks produced is 6*(m+1) for the two-sample
      case and 2*(m+1) for the one-sample case, where m=number of covariates.

* For example, if there is one covariate 'IQ', and a two sample analysis
   is carried out ('-setA' and '-setB' both used), then the output
   dataset will contain the following 12 (6*2) sub-bricks:
      #0  SetA-SetB_mean      = difference of means [covariates removed]
      #1  SetA-SetB_Tstat
      #2  SetA-SetB_IQ        = difference of slopes wrt covariate IQ
      #3  SetA-SetB_IQ_Tstat
      #4  SetA_mean           = mean of SetA [covariates removed]
      #5  SetA_Tstat
      #6  SetA_IQ             = slope of SetA wrt covariate IQ
      #7  SetA_IQ_Tstat
      #8  SetB_mean           = mean of SetB [covariates removed]
      #9  SetB_Tstat
      #10 SetB_IQ             = slope of SetB wrt covariate IQ
      #11 SetB_IQ_Tstat

* In the above, 'wrt' is standard mathematical shorthand for the
   phrase 'with respect to'.

* If option '-BminusA' is given, then the 'SetA-SetB' sub-bricks would
   be labeled 'SetB-SetA' instead, of course.

* If option '-toz' is used, the 'Tstat' will be replaced with 'Zscr'
   in the statistical sub-brick labels.

* If the long form of '-setA' is used, or '-labelA' is given, then
   'SetA' in the sub-brick labels above is replaced with the
   corresponding SETNAME.  (Mutatis mutandis for 'SetB'.)

* If you produce a NIfTI-1 (.nii) file, then the sub-brick labels are
   saved in the AFNI extension in the .nii file.  Processing further
   in non-AFNI programs will probably cause these labels to be lost
   (along with other AFNI niceties, such as the history field).

* If you are doing a 2-sample run and don't want the 1-sample results,
   then the '-no1sam' option can be used to eliminate these sub-bricks
   from the output, saving space and time and mental energy.

* The largest Tstat that will be output is 99.
* The largest Zscr that will be output is 13.
  ++ FYI: the 1-sided Gaussian tail probability of z=13 is 6.1e-39.

-------------------
HOW COVARIATES WORK
-------------------

Covariates work by forming a regression problem for each voxel, to
estimate the mean of the input data and the slopes of the data with
respect to variations in the covariates.

For each input set of sub-bricks, a matrix is assembled.  There is one
row for each sub-brick, and one column for each covariate, plus one
more column for the mean.  So if there are 5 sub-bricks and 2 covariates,
the matrix would look like so

     [ 1  0.3  1.7 ]
     [ 1  0.5  2.2 ]
 X = [ 1  2.3  3.3 ]
     [ 1  5.7  7.9 ]
     [ 1  1.2  4.9 ]

The first column is all 1s, and models the mean value of the betas.
The remaining columns are the covariates for each sub-brick.  (The
numbers above are values I just made up, obviously.)

The matrix is centered by removing the mean from each column except
the first one.  In the above matrix, the mean of column #2 is 2,
and the mean of column #3 is 4, so the centered matrix is

      [ 1 -1.7 -2.3 ]
      [ 1 -1.5 -1.8 ]
 Xc = [ 1  0.3 -0.7 ]
      [ 1  3.7  3.9 ]
      [ 1 -0.8  0.9 ]

(N.B.: more than one centering option is available; this is the default.)

The set of equations to be solved is [Xc] [b] = [z], where [b] is
the column vector desired (first element = de-covariate-ized mean
of the data values, remaining elements = slopes of data values
with respect to the covariates), and [z] is the column vector of
data values extracted from the input datasets.

This set of equations is solved by forming the pseudo-inverse of the
matrix [Xc]: [Xp] = inverse[Xc'Xc] [Xc'], so that [b] = [Xp] [z].
(Here, ' means transpose.) For the sample matrix above, we have

      [  0.2         0.2         0.2       0.2        0.2      ]
 Xp = [  0.0431649  -0.015954    0.252887  0.166557  -0.446654 ]
      [ -0.126519   -0.0590721  -0.231052  0.0219866  0.394657 ]

Because of the centering, the first column of [Xc] is orthgonal to
the other columns, so the first row of [Xp] is all 1/N, where N is
the number of data points (here, N=5).

In reality, the pseudo-inverse [Xp] is computed using the SVD, which
means that even a column of all zero covariates will not cause a
singular matrix problem.

In addition, the matrix [Xi] = inverse[Xc'Xc] is computed.  Its diagonal
elements are needed in the t-test computations.  In the above example,

      [ 0.2 0        0       ]
 Xi = [ 0   0.29331 -0.23556 ]
      [ 0  -0.23556  0.22912 ]

For a 1-sample t-test, the regression values computed in [b] are the
'_mean' values stored in the output dataset.  The t-statistics are
computed by first calculating the regression residual vector
  [r] = [Xc][b] - [z]  (the mismatch between the data and the model)
and then the estimated variance v of the residuals is given by

        i=N
  q = sum  { r[i]*r[i] }  and then  v = q / (N-m)
        i=1

where N=number of data points and m=number of matrix columns=number of
parameters estimated in the regression model.  The t-statistic for the
k-th element of [b] is then given by

  t[k] = b[k] / sqrt( v * Xi[k,k] )

Note that for the first element, the factor Xi[1,1] is just 1/N, as
is the case in the simple (no covariates) t-test.

For a 2-sample unpaired t-test, the '_mean' output for the k-th column
of the matrix [X] is bA[k]-bB[k] where 'A' and 'B' refer to the 2 input
collections of datasets.  The t-statistic is computed by

  vAB  = (qA+qB) / (NA+NB-2*m)

  t[k] = (bA[k]-bB[k]) / sqrt( vAB * (XiA[k,k]+XiB[k,k]) )

For a 2-sample paired t-test, the t-statistic is a little different:

        i=N
  q = sum  { (rA[i]-rB[i])^2 }  and then  vAB = q / (N-m)
        i=1

and then

  t[k] = (bA[k]-bB[k]) / sqrt( vAB * XiA[k,k] )

A paired t-test is basically a 1-sample test with the 'data' being
the difference [zA]-[zB] of the two input samples.

Note the central role of the diagonal elements of the [Xi] matrix.
These numbers are the variances of the estimates of the [b] if the
data [z] is corrupted by additive white noise with variance=1.
(In the case of an all zero column of covariates, the SVD inversion)
(that yields [Xi] will make that diagonal element 0.  Division by 0)
(being a not-good thing, in such a case Xi[k,k] is replaced by 1e9.)

For cases with voxel-wise covariates, each voxel gets a different
[X] matrix, and so the matrix inversions are carried out many many
times.  If the covariates are fixed values, then only one set of
matrix inversions needs to be carried out.

-------------------------
VARIOUS LINKS OF INTEREST
-------------------------
* http://en.wikipedia.org/wiki/T_test
* http://www.statsoft.com/textbook/basic-statistics/
* http://en.wikipedia.org/wiki/Mutatis_mutandis

----------------------------------------------------
AUTHOR -- RW Cox -- don't whine TO me; wine WITH me.
----------------------------------------------------

++ Compile date = Jul  5 2011

